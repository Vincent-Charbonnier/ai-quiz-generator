replicaCount:
  frontend: 1
  backend: 1
  rag: 1

image:
  frontend:
    repository: vinchar/ai-quiz-generator-frontend
    tag: "0.4"
    pullPolicy: IfNotPresent
  backend:
    repository: vinchar/ai-quiz-generator-backend
    tag: "0.3"
    pullPolicy: IfNotPresent
  rag:
    repository: vinchar/ai-quiz-generator-rag
    tag: "0.3"
    pullPolicy: IfNotPresent

frontend:
  nginx:
    enabled: true
    config: |
      server {
          listen 80;
          root /usr/share/nginx/html;
          index index.html;

          client_max_body_size 50m;

          location /api/ {
              proxy_pass http://backend:3001;
              proxy_set_header Host $host;
              proxy_set_header X-Real-IP $remote_addr;
              proxy_read_timeout 300s;
              proxy_send_timeout 300s;
              proxy_connect_timeout 60s;
          }

          location /health {
              proxy_pass http://backend:3001/health;
              proxy_set_header Host $host;
              proxy_set_header X-Real-IP $remote_addr;
          }

          location / {
              try_files $uri $uri/ /index.html;
          }
      }

service:
  frontend:
    type: ClusterIP
    port: 80
  backend:
    # IMPORTANT: nginx in the frontend image proxies to http://backend:3001
    # Keep this name as "backend" unless you rebuild the frontend image.
    name: backend
    type: ClusterIP
    port: 3001
  rag:
    name: rag
    type: ClusterIP
    port: 8000

ragConfig:
  pdfUrl: ""
  embeddingEndpoint: "https://nv-embedqa-e5-v5.vincent-charbon-8e171347.serving.pcaidev.ai.greendatacenter.com/v1"
  embeddingToken: ""
  embeddingModel: "nvidia/nv-embedqa-e5-v5"
  llmEndpoint: "https://gpt-oss-120b.project-user-claudio-luethi.serving.pcaidev.ai.greendatacenter.com/v1"
  llmToken: ""
  llmModel: "openai/gpt-oss-120b"
  chunkSize: 512
  chunkOverlap: 64
  topK: 6
  chromaUrl: "http://chroma-db-service.chroma.svc.cluster.local:8000"
  chromaSslVerify: "true"

configMap:
  create: true
  name: ""

secret:
  create: true
  name: ""

resources:
  frontend:
    limits: {}
    requests: {}
  backend:
    limits: {}
    requests: {}
  rag:
    limits:
      cpu: "2"
      memory: "16Gi"
    requests:
      cpu: "1"
      memory: "8Gi"

backend:
  configPath: "/data/quiz-config.json"
  persistence:
    enabled: true
    accessModes:
      - ReadWriteOnce
    size: 1Gi
    storageClassName: ""
    mountPath: "/data"

nodeSelector: {}
tolerations: []
affinity: {}

readinessProbe:
  frontend:
    path: "/"
    initialDelaySeconds: 5
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 3
    successThreshold: 1
  backend:
    path: "/health"
    initialDelaySeconds: 5
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 3
    successThreshold: 1
  rag:
    path: "/healthz"
    initialDelaySeconds: 20
    periodSeconds: 15
    timeoutSeconds: 10
    failureThreshold: 3
    successThreshold: 1

livenessProbe:
  frontend:
    path: "/"
    initialDelaySeconds: 30
    periodSeconds: 20
    timeoutSeconds: 5
    failureThreshold: 3
    successThreshold: 1
  backend:
    path: "/health"
    initialDelaySeconds: 30
    periodSeconds: 20
    timeoutSeconds: 5
    failureThreshold: 3
    successThreshold: 1
  rag:
    path: "/healthz"
    initialDelaySeconds: 60
    periodSeconds: 30
    timeoutSeconds: 10
    failureThreshold: 3
    successThreshold: 1

hpa:
  enabled: false
  minReplicas: 1
  maxReplicas: 3
  targetCPUUtilizationPercentage: 60

ingress:
  enabled: false
  host: ai-quiz.example.com
  annotations: {}

ezua:
  virtualService:
    endpoint: "ai-quiz.${DOMAIN_NAME}"
    domain: "${DOMAIN_NAME}"
    istioGateway: "istio-system/ezaf-gateway"
    timeout: "300s"
